{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device 객체\n",
    "print(device)\n",
    "\n",
    "#print(fm.findSystemFonts(fontpaths=None, fontext='ttf'))\n",
    "\n",
    "fontpath = 'C:/Windows/Fonts/NanumGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=10).get_name()\n",
    "plt.rc('font', family=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(), # 데이터 증진(augmentation)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='C:/Users/kangb/capstoneDesign/Back-end/IdeaProjects/imageDownloader/Image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'style3'), transforms_train)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋 크기: 582\n",
      "학습 클래스: ['모던', '스포티', '캐주얼', '페미닌']\n"
     ]
    }
   ],
   "source": [
    "print('학습 데이터셋 크기:', len(train_datasets))\n",
    "#print('테스트 데이터셋 크기:', len(valid_datasets))\n",
    "\n",
    "class_names = train_datasets.classes\n",
    "print('학습 클래스:', class_names)\n",
    "\n",
    "def imshow(input, title):\n",
    "    # torch.Tensor를 numpy 객체로 변환\n",
    "    input = input.numpy().transpose((1, 2, 0))\n",
    "    # 이미지 정규화 해제하기\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    input = std * input + mean\n",
    "    input = np.clip(input, 0, 1)\n",
    "    # 이미지 출력\n",
    "    plt.imshow(input)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 경로\n",
    "model_path = './weight/style_only_model_best_epoch.pth'\n",
    "\n",
    "# 모델 로드\n",
    "loaded_model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'in_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6464/1689560577.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnum_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# 전이 학습(transfer learning): 모델의 출력 뉴런 수를 3개로 교체하여 마지막 레이어 다시 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# transfer learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model.fc = nn.Sequential(     \n",
      "\u001b[1;32mc:\\Users\\kangb\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m   1186\u001b[0m             type(self).__name__, name))\n\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'in_features'"
     ]
    }
   ],
   "source": [
    "model = loaded_model\n",
    "num_features = model.fc.in_features\n",
    "# 전이 학습(transfer learning): 모델의 출력 뉴런 수를 3개로 교체하여 마지막 레이어 다시 학습\n",
    "# transfer learning\n",
    "model.fc = nn.Sequential(     \n",
    "    nn.Linear(num_features, 256),        # 마지막 완전히 연결된 계층에 대한 입력은 선형 계층, 256개의 출력값을 가짐\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, num_features),      # Since 10 possible outputs = 10 classes\n",
    "    nn.LogSoftmax(dim=1)              # For using NLLLoss()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "best_epoch = None\n",
    "best_loss = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 2.3751 Acc: 29.0859% Time: 296.7641s\n",
      "best_loss: 2.3751 \t best_epoch: 0\n",
      "#1 Loss: 1.1644 Acc: 49.8615% Time: 353.6636s\n",
      "best_loss: 1.1644 \t best_epoch: 1\n",
      "#2 Loss: 0.8538 Acc: 64.2659% Time: 320.8868s\n",
      "best_loss: 0.8538 \t best_epoch: 2\n",
      "#3 Loss: 0.7297 Acc: 72.2992% Time: 278.8234s\n",
      "best_loss: 0.7297 \t best_epoch: 3\n",
      "#4 Loss: 0.7549 Acc: 74.2382% Time: 264.1837s\n",
      "#5 Loss: 0.5646 Acc: 79.2244% Time: 258.0956s\n",
      "best_loss: 0.5646 \t best_epoch: 5\n",
      "#6 Loss: 0.5183 Acc: 80.3324% Time: 253.2672s\n",
      "best_loss: 0.5183 \t best_epoch: 6\n",
      "#7 Loss: 0.5335 Acc: 83.3795% Time: 237.2040s\n",
      "#8 Loss: 0.4147 Acc: 86.7036% Time: 236.8358s\n",
      "best_loss: 0.4147 \t best_epoch: 8\n",
      "#9 Loss: 0.3893 Acc: 85.3186% Time: 235.0952s\n",
      "best_loss: 0.3893 \t best_epoch: 9\n",
      "#10 Loss: 0.4069 Acc: 88.0886% Time: 236.8759s\n",
      "#11 Loss: 0.3502 Acc: 88.3656% Time: 236.2947s\n",
      "best_loss: 0.3502 \t best_epoch: 11\n",
      "#12 Loss: 0.3031 Acc: 89.7507% Time: 238.9359s\n",
      "best_loss: 0.3031 \t best_epoch: 12\n",
      "#13 Loss: 0.2067 Acc: 91.6898% Time: 237.0726s\n",
      "best_loss: 0.2067 \t best_epoch: 13\n",
      "#14 Loss: 0.2271 Acc: 93.3518% Time: 237.4936s\n",
      "#15 Loss: 0.3042 Acc: 90.5817% Time: 237.7314s\n",
      "#16 Loss: 0.3869 Acc: 85.5956% Time: 235.4180s\n",
      "#17 Loss: 0.3862 Acc: 88.0886% Time: 234.4508s\n",
      "#18 Loss: 0.3108 Acc: 88.6427% Time: 241.7689s\n",
      "#19 Loss: 0.2732 Acc: 91.6898% Time: 236.4393s\n"
     ]
    }
   ],
   "source": [
    "''' Train '''\n",
    "# 전체 반복(epoch) 수 만큼 반복하며\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "\n",
    "    # 배치 단위로 학습 데이터 불러오기\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 모델에 입력(forward)하고 결과 계산\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 역전파를 통해 기울기(gradient) 계산 및 학습 진행\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_datasets)\n",
    "    epoch_acc = running_corrects / len(train_datasets) * 100.\n",
    "\n",
    "    # 학습 과정 중에 결과 출력\n",
    "    print('#{} Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        print(\"best_loss: {:.4f} \\t best_epoch: {}\".format(best_loss, best_epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./weight',exist_ok=True)\n",
    "torch.save(model,'./weight/style_only_model_best_epoch.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
