{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device 객체\n",
    "print(device)\n",
    "\n",
    "#print(fm.findSystemFonts(fontpaths=None, fontext='ttf'))\n",
    "\n",
    "fontpath = 'C:/Windows/Fonts/NanumGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=10).get_name()\n",
    "plt.rc('font', family=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(), # 데이터 증진(augmentation)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='C:/Users/kangb/capstoneDesign/Back-end/IdeaProjects/imageDownloader/Image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'style'), transforms_train)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋 크기: 2439\n",
      "학습 클래스: ['모던', '스포티', '캐주얼', '페미닌']\n"
     ]
    }
   ],
   "source": [
    "print('학습 데이터셋 크기:', len(train_datasets))\n",
    "#print('테스트 데이터셋 크기:', len(valid_datasets))\n",
    "\n",
    "class_names = train_datasets.classes\n",
    "print('학습 클래스:', class_names)\n",
    "\n",
    "def imshow(input, title):\n",
    "    # torch.Tensor를 numpy 객체로 변환\n",
    "    input = input.numpy().transpose((1, 2, 0))\n",
    "    # 이미지 정규화 해제하기\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    input = std * input + mean\n",
    "    input = np.clip(input, 0, 1)\n",
    "    # 이미지 출력\n",
    "    plt.imshow(input)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet34(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "# 전이 학습(transfer learning): 모델의 출력 뉴런 수를 3개로 교체하여 마지막 레이어 다시 학습\n",
    "# transfer learning\n",
    "model.fc = nn.Sequential(     \n",
    "    nn.Linear(num_features, 256),        # 마지막 완전히 연결된 계층에 대한 입력은 선형 계층, 256개의 출력값을 가짐\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, num_features),      # Since 10 possible outputs = 10 classes\n",
    "    nn.LogSoftmax(dim=1)              # For using NLLLoss()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "best_epoch = None\n",
    "best_loss = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 1.6422 Acc: 32.5953% Time: 1435.0680s\n",
      "best_loss: 1.6422 \t best_epoch: 0\n",
      "#1 Loss: 1.3156 Acc: 42.8044% Time: 1422.7422s\n",
      "best_loss: 1.3156 \t best_epoch: 1\n",
      "#2 Loss: 1.2439 Acc: 46.8225% Time: 1397.2885s\n",
      "best_loss: 1.2439 \t best_epoch: 2\n",
      "#3 Loss: 1.1432 Acc: 51.4555% Time: 1388.0430s\n",
      "best_loss: 1.1432 \t best_epoch: 3\n",
      "#4 Loss: 1.0705 Acc: 55.6786% Time: 1389.7241s\n",
      "best_loss: 1.0705 \t best_epoch: 4\n",
      "#5 Loss: 0.9863 Acc: 59.9836% Time: 1395.1946s\n",
      "best_loss: 0.9863 \t best_epoch: 5\n",
      "#6 Loss: 0.9051 Acc: 64.0426% Time: 1390.4435s\n",
      "best_loss: 0.9051 \t best_epoch: 6\n",
      "#7 Loss: 0.8605 Acc: 66.9947% Time: 1386.1064s\n",
      "best_loss: 0.8605 \t best_epoch: 7\n",
      "#8 Loss: 0.7799 Acc: 71.0537% Time: 1522.8471s\n",
      "best_loss: 0.7799 \t best_epoch: 8\n",
      "#9 Loss: 0.7704 Acc: 70.8487% Time: 1406.1645s\n",
      "best_loss: 0.7704 \t best_epoch: 9\n",
      "#10 Loss: 0.6679 Acc: 75.4818% Time: 1353.2998s\n",
      "best_loss: 0.6679 \t best_epoch: 10\n",
      "#11 Loss: 0.6270 Acc: 76.4658% Time: 1350.3327s\n",
      "best_loss: 0.6270 \t best_epoch: 11\n",
      "#12 Loss: 0.5975 Acc: 78.6388% Time: 1416.7505s\n",
      "best_loss: 0.5975 \t best_epoch: 12\n",
      "#13 Loss: 0.5356 Acc: 81.1398% Time: 1372.6384s\n",
      "best_loss: 0.5356 \t best_epoch: 13\n",
      "#14 Loss: 0.5319 Acc: 81.5908% Time: 1403.2444s\n",
      "best_loss: 0.5319 \t best_epoch: 14\n",
      "#15 Loss: 0.4550 Acc: 84.6248% Time: 1379.8909s\n",
      "best_loss: 0.4550 \t best_epoch: 15\n",
      "#16 Loss: 0.4433 Acc: 84.8708% Time: 1405.9641s\n",
      "best_loss: 0.4433 \t best_epoch: 16\n",
      "#17 Loss: 0.4212 Acc: 84.9118% Time: 1437.4898s\n",
      "best_loss: 0.4212 \t best_epoch: 17\n",
      "#18 Loss: 0.3915 Acc: 86.7159% Time: 1380.7073s\n",
      "best_loss: 0.3915 \t best_epoch: 18\n",
      "#19 Loss: 0.3307 Acc: 89.0119% Time: 1396.1803s\n",
      "best_loss: 0.3307 \t best_epoch: 19\n",
      "#20 Loss: 0.3136 Acc: 89.7499% Time: 1390.7284s\n",
      "best_loss: 0.3136 \t best_epoch: 20\n",
      "#21 Loss: 0.3249 Acc: 89.0529% Time: 1377.6531s\n",
      "#22 Loss: 0.2831 Acc: 91.2259% Time: 1386.7341s\n",
      "best_loss: 0.2831 \t best_epoch: 22\n",
      "#23 Loss: 0.2527 Acc: 91.4309% Time: 1374.3321s\n",
      "best_loss: 0.2527 \t best_epoch: 23\n",
      "#24 Loss: 0.2410 Acc: 91.9639% Time: 1433.4443s\n",
      "best_loss: 0.2410 \t best_epoch: 24\n",
      "#25 Loss: 0.2378 Acc: 92.2509% Time: 1388.3924s\n",
      "best_loss: 0.2378 \t best_epoch: 25\n",
      "#26 Loss: 0.2127 Acc: 93.2759% Time: 1388.8634s\n",
      "best_loss: 0.2127 \t best_epoch: 26\n",
      "#27 Loss: 0.1913 Acc: 94.1369% Time: 1386.7092s\n",
      "best_loss: 0.1913 \t best_epoch: 27\n",
      "#28 Loss: 0.2368 Acc: 93.2759% Time: 1487.2578s\n",
      "#29 Loss: 0.2212 Acc: 93.2759% Time: 1499.7997s\n",
      "#30 Loss: 0.1671 Acc: 94.7109% Time: 1432.4783s\n",
      "best_loss: 0.1671 \t best_epoch: 30\n",
      "#31 Loss: 0.1539 Acc: 95.5720% Time: 1376.5396s\n",
      "best_loss: 0.1539 \t best_epoch: 31\n",
      "#32 Loss: 0.1746 Acc: 95.0389% Time: 1443.9413s\n",
      "#33 Loss: 0.1814 Acc: 94.5060% Time: 1383.7492s\n",
      "#34 Loss: 0.1388 Acc: 95.4080% Time: 1381.4911s\n",
      "best_loss: 0.1388 \t best_epoch: 34\n",
      "#35 Loss: 0.1284 Acc: 95.9410% Time: 1382.3842s\n",
      "best_loss: 0.1284 \t best_epoch: 35\n",
      "#36 Loss: 0.1460 Acc: 95.5310% Time: 1381.0156s\n",
      "#37 Loss: 0.1555 Acc: 95.3670% Time: 1381.9809s\n",
      "#38 Loss: 0.1315 Acc: 95.9820% Time: 1382.3182s\n",
      "#39 Loss: 0.1293 Acc: 96.0640% Time: 1381.8412s\n",
      "#40 Loss: 0.1208 Acc: 96.7200% Time: 1398.7126s\n",
      "best_loss: 0.1208 \t best_epoch: 40\n",
      "#41 Loss: 0.1137 Acc: 96.4330% Time: 1379.2572s\n",
      "best_loss: 0.1137 \t best_epoch: 41\n",
      "#42 Loss: 0.1153 Acc: 96.4330% Time: 1387.0527s\n",
      "#43 Loss: 0.0984 Acc: 97.1300% Time: 1391.1168s\n",
      "best_loss: 0.0984 \t best_epoch: 43\n",
      "#44 Loss: 0.1159 Acc: 96.7610% Time: 1380.8305s\n",
      "#45 Loss: 0.0997 Acc: 97.4990% Time: 1387.1856s\n",
      "#46 Loss: 0.1045 Acc: 97.4170% Time: 1378.7571s\n",
      "#47 Loss: 0.1040 Acc: 96.8840% Time: 1442.7153s\n",
      "#48 Loss: 0.0811 Acc: 97.0480% Time: 1435.7315s\n",
      "best_loss: 0.0811 \t best_epoch: 48\n",
      "#49 Loss: 0.0783 Acc: 97.9500% Time: 1393.4109s\n",
      "best_loss: 0.0783 \t best_epoch: 49\n"
     ]
    }
   ],
   "source": [
    "''' Train '''\n",
    "# 전체 반복(epoch) 수 만큼 반복하며\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "\n",
    "    # 배치 단위로 학습 데이터 불러오기\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 모델에 입력(forward)하고 결과 계산\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 역전파를 통해 기울기(gradient) 계산 및 학습 진행\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_datasets)\n",
    "    epoch_acc = running_corrects / len(train_datasets) * 100.\n",
    "\n",
    "    # 학습 과정 중에 결과 출력\n",
    "    print('#{} Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        print(\"best_loss: {:.4f} \\t best_epoch: {}\".format(best_loss, best_epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./weight',exist_ok=True)\n",
    "torch.save(model,'./weight/style_model_best_epoch.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
